{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "======================================================<br>\n", "Face classification using Haar-like feature descriptor<br>\n", "======================================================<br>\n", "Haar-like feature descriptors were successfully used to implement the first<br>\n", "real-time face detector [1]_. Inspired by this application, we propose an<br>\n", "example illustrating the extraction, selection, and classification of Haar-like<br>\n", "features to detect faces vs. non-faces.<br>\n", "Notes<br>\n", "-----<br>\n", "This example relies on `scikit-learn <https://scikit-learn.org/>`_ for feature<br>\n", "selection and classification.<br>\n", "References<br>\n", "----------<br>\n", ".. [1] Viola, Paul, and Michael J. Jones. \"Robust real-time face<br>\n", "       detection.\" International journal of computer vision 57.2<br>\n", "       (2004): 137-154.<br>\n", "       https://www.merl.com/publications/docs/TR2004-043.pdf<br>\n", "       :DOI:`10.1109/CVPR.2001.990517`<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "from time import time"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from dask import delayed"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import roc_auc_score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from skimage.data import lfw_subset\n", "from skimage.transform import integral_image\n", "from skimage.feature import haar_like_feature\n", "from skimage.feature import haar_like_feature_coord\n", "from skimage.feature import draw_haar_like_feature"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#########################################################################<br>\n", "The procedure to extract the Haar-like features from an image is relatively<br>\n", "simple. Firstly, a region of interest (ROI) is defined. Secondly, the<br>\n", "integral image within this ROI is computed. Finally, the integral image is<br>\n", "used to extract the features."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@delayed\n", "def extract_feature_image(img, feature_type, feature_coord=None):\n", "    \"\"\"Extract the haar feature for the current image\"\"\"\n", "    ii = integral_image(img)\n", "    return haar_like_feature(ii, 0, 0, ii.shape[0], ii.shape[1],\n", "                             feature_type=feature_type,\n", "                             feature_coord=feature_coord)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#########################################################################<br>\n", "We use a subset of CBCL dataset which is composed of 100 face images and<br>\n", "100 non-face images. Each image has been resized to a ROI of 19 by 19<br>\n", "pixels. We select 75 images from each group to train a classifier and<br>\n", "determine the most salient features. The remaining 25 images from each<br>\n", "class are used to assess the performance of the classifier."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["images = lfw_subset()\n", "# To speed up the example, extract the two types of features only\n", "feature_types = ['type-2-x', 'type-2-y']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Build a computation graph using Dask. This allows the use of multiple<br>\n", "CPU cores later during the actual computation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = delayed(extract_feature_image(img, feature_types) for img in images)\n", "# Compute the result\n", "t_start = time()\n", "X = np.array(X.compute(scheduler='single-threaded'))\n", "time_full_feature_comp = time() - t_start"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Label images (100 faces and 100 non-faces)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y = np.array([1] * 100 + [0] * 100)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=150,\n", "                                                    random_state=0,\n", "                                                    stratify=y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Extract all possible features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["feature_coord, feature_type = \\\n", "    haar_like_feature_coord(width=images.shape[2], height=images.shape[1],\n", "                            feature_type=feature_types)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#########################################################################<br>\n", "A random forest classifier can be trained in order to select the most<br>\n", "salient features, specifically for face classification. The idea is to<br>\n", "determine which features are most often used by the ensemble of trees.<br>\n", "By using only the most salient features in subsequent steps, we can<br>\n", "drastically speed up the computation while retaining accuracy."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train a random forest classifier and assess its performance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clf = RandomForestClassifier(n_estimators=1000, max_depth=None,\n", "                             max_features=100, n_jobs=-1, random_state=0)\n", "t_start = time()\n", "clf.fit(X_train, y_train)\n", "time_full_train = time() - t_start\n", "auc_full_features = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sort features in order of importance and plot the six most significant"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["idx_sorted = np.argsort(clf.feature_importances_)[::-1]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(3, 2)\n", "for idx, ax in enumerate(axes.ravel()):\n", "    image = images[0]\n", "    image = draw_haar_like_feature(image, 0, 0,\n", "                                   images.shape[2],\n", "                                   images.shape[1],\n", "                                   [feature_coord[idx_sorted[idx]]])\n", "    ax.imshow(image)\n", "    ax.set_xticks([])\n", "    ax.set_yticks([])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["_ = fig.suptitle('The most important features')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#########################################################################<br>\n", "We can select the most important features by checking the cumulative sum<br>\n", "of the feature importance. In this example, we keep the features<br>\n", "representing 70% of the cumulative value (which corresponds to using only 3%<br>\n", "of the total number of features)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cdf_feature_importances = np.cumsum(clf.feature_importances_[idx_sorted])\n", "cdf_feature_importances /= cdf_feature_importances[-1]  # divide by max value\n", "sig_feature_count = np.count_nonzero(cdf_feature_importances < 0.7)\n", "sig_feature_percent = round(sig_feature_count /\n", "                            len(cdf_feature_importances) * 100, 1)\n", "print(('{} features, or {}%, account for 70% of branch points in the '\n", "       'random forest.').format(sig_feature_count, sig_feature_percent))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Select the determined number of most informative features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["feature_coord_sel = feature_coord[idx_sorted[:sig_feature_count]]\n", "feature_type_sel = feature_type[idx_sorted[:sig_feature_count]]\n", "# Note: it is also possible to select the features directly from the matrix X,\n", "# but we would like to emphasize the usage of `feature_coord` and `feature_type`\n", "# to recompute a subset of desired features."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Build the computational graph using Dask"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = delayed(extract_feature_image(img, feature_type_sel, feature_coord_sel)\n", "            for img in images)\n", "# Compute the result\n", "t_start = time()\n", "X = np.array(X.compute(scheduler='single-threaded'))\n", "time_subs_feature_comp = time() - t_start"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y = np.array([1] * 100 + [0] * 100)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=150,\n", "                                                    random_state=0,\n", "                                                    stratify=y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#########################################################################<br>\n", "Once the features are extracted, we can train and test a new classifier."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["t_start = time()\n", "clf.fit(X_train, y_train)\n", "time_subs_train = time() - t_start"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["auc_subs_features = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["summary = (('Computing the full feature set took {:.3f}s, plus {:.3f}s '\n", "            'training, for an AUC of {:.2f}. Computing the restricted '\n", "            'feature set took {:.3f}s, plus {:.3f}s training, '\n", "            'for an AUC of {:.2f}.')\n", "           .format(time_full_feature_comp, time_full_train,\n", "                   auc_full_features, time_subs_feature_comp,\n", "                   time_subs_train, auc_subs_features))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(summary)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}