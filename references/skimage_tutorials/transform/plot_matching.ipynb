{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "============================<br>\n", "Robust matching using RANSAC<br>\n", "============================<br>\n", "In this simplified example we first generate two synthetic images as if they<br>\n", "were taken from different view points.<br>\n", "In the next step we find interest points in both images and find<br>\n", "correspondences based on a weighted sum of squared differences of a small<br>\n", "neighborhood around them. Note, that this measure is only robust towards<br>\n", "linear radiometric and not geometric distortions and is thus only usable with<br>\n", "slight view point changes.<br>\n", "After finding the correspondences we end up having a set of source and<br>\n", "destination coordinates which can be used to estimate the geometric<br>\n", "transformation between both images. However, many of the correspondences are<br>\n", "faulty and simply estimating the parameter set with all coordinates is not<br>\n", "sufficient. Therefore, the RANSAC algorithm is used on top of the normal model<br>\n", "to robustly estimate the parameter set by detecting outliers.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from matplotlib import pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from skimage import data\n", "from skimage.util import img_as_float\n", "from skimage.feature import (corner_harris, corner_subpix, corner_peaks,\n", "                             plot_matches)\n", "from skimage.transform import warp, AffineTransform\n", "from skimage.exposure import rescale_intensity\n", "from skimage.color import rgb2gray\n", "from skimage.measure import ransac"]}, {"cell_type": "markdown", "metadata": {}, "source": ["generate synthetic checkerboard image and add gradient for the later matching"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["checkerboard = img_as_float(data.checkerboard())\n", "img_orig = np.zeros(list(checkerboard.shape) + [3])\n", "img_orig[..., 0] = checkerboard\n", "gradient_r, gradient_c = (np.mgrid[0:img_orig.shape[0],\n", "                                   0:img_orig.shape[1]]\n", "                          / float(img_orig.shape[0]))\n", "img_orig[..., 1] = gradient_r\n", "img_orig[..., 2] = gradient_c\n", "img_orig = rescale_intensity(img_orig)\n", "img_orig_gray = rgb2gray(img_orig)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["warp synthetic image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tform = AffineTransform(scale=(0.9, 0.9), rotation=0.2, translation=(20, -10))\n", "img_warped = warp(img_orig, tform.inverse, output_shape=(200, 200))\n", "img_warped_gray = rgb2gray(img_warped)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["extract corners using Harris' corner measure"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["coords_orig = corner_peaks(corner_harris(img_orig_gray), threshold_rel=0.001,\n", "                           min_distance=5)\n", "coords_warped = corner_peaks(corner_harris(img_warped_gray),\n", "                             threshold_rel=0.001, min_distance=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["determine sub-pixel corner position"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["coords_orig_subpix = corner_subpix(img_orig_gray, coords_orig, window_size=9)\n", "coords_warped_subpix = corner_subpix(img_warped_gray, coords_warped,\n", "                                     window_size=9)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def gaussian_weights(window_ext, sigma=1):\n", "    y, x = np.mgrid[-window_ext:window_ext+1, -window_ext:window_ext+1]\n", "    g = np.zeros(y.shape, dtype=np.double)\n", "    g[:] = np.exp(-0.5 * (x**2 / sigma**2 + y**2 / sigma**2))\n", "    g /= 2 * np.pi * sigma * sigma\n", "    return g"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def match_corner(coord, window_ext=5):\n", "    r, c = np.round(coord).astype(np.intp)\n", "    window_orig = img_orig[r-window_ext:r+window_ext+1,\n", "                           c-window_ext:c+window_ext+1, :]\n\n", "    # weight pixels depending on distance to center pixel\n", "    weights = gaussian_weights(window_ext, 3)\n", "    weights = np.dstack((weights, weights, weights))\n\n", "    # compute sum of squared differences to all corners in warped image\n", "    SSDs = []\n", "    for cr, cc in coords_warped:\n", "        window_warped = img_warped[cr-window_ext:cr+window_ext+1,\n", "                                   cc-window_ext:cc+window_ext+1, :]\n", "        SSD = np.sum(weights * (window_orig - window_warped)**2)\n", "        SSDs.append(SSD)\n\n", "    # use corner with minimum SSD as correspondence\n", "    min_idx = np.argmin(SSDs)\n", "    return coords_warped_subpix[min_idx]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["find correspondences using simple weighted sum of squared differences"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["src = []\n", "dst = []\n", "for coord in coords_orig_subpix:\n", "    src.append(coord)\n", "    dst.append(match_corner(coord))\n", "src = np.array(src)\n", "dst = np.array(dst)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["estimate affine transform model using all coordinates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = AffineTransform()\n", "model.estimate(src, dst)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["robustly estimate affine transform model with RANSAC"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_robust, inliers = ransac((src, dst), AffineTransform, min_samples=3,\n", "                               residual_threshold=2, max_trials=100)\n", "outliers = inliers == False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["compare \"true\" and estimated transform parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Ground truth:\")\n", "print(f\"Scale: ({tform.scale[1]:.4f}, {tform.scale[0]:.4f}), \"\n", "      f\"Translation: ({tform.translation[1]:.4f}, \"\n", "      f\"{tform.translation[0]:.4f}), \"\n", "      f\"Rotation: {-tform.rotation:.4f}\")\n", "print(\"Affine transform:\")\n", "print(f\"Scale: ({model.scale[0]:.4f}, {model.scale[1]:.4f}), \"\n", "      f\"Translation: ({model.translation[0]:.4f}, \"\n", "      f\"{model.translation[1]:.4f}), \"\n", "      f\"Rotation: {model.rotation:.4f}\")\n", "print(\"RANSAC:\")\n", "print(f\"Scale: ({model_robust.scale[0]:.4f}, {model_robust.scale[1]:.4f}), \"\n", "      f\"Translation: ({model_robust.translation[0]:.4f}, \"\n", "      f\"{model_robust.translation[1]:.4f}), \"\n", "      f\"Rotation: {model_robust.rotation:.4f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["visualize correspondence"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(nrows=2, ncols=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.gray()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["inlier_idxs = np.nonzero(inliers)[0]\n", "plot_matches(ax[0], img_orig_gray, img_warped_gray, src, dst,\n", "             np.column_stack((inlier_idxs, inlier_idxs)), matches_color='b')\n", "ax[0].axis('off')\n", "ax[0].set_title('Correct correspondences')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["outlier_idxs = np.nonzero(outliers)[0]\n", "plot_matches(ax[1], img_orig_gray, img_warped_gray, src, dst,\n", "             np.column_stack((outlier_idxs, outlier_idxs)), matches_color='r')\n", "ax[1].axis('off')\n", "ax[1].set_title('Faulty correspondences')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}